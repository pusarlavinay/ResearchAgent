{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Explorer\n",
    "\n",
    "Inspect tables, recent documents, and sample chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "if (ROOT / 'backend').exists():\n",
    "    PROJECT_ROOT = ROOT\n",
    "elif ROOT.name == 'notebook':\n",
    "    PROJECT_ROOT = ROOT.parent\n",
    "else:\n",
    "    PROJECT_ROOT = ROOT\n",
    "\n",
    "BACKEND_DIR = PROJECT_ROOT / 'backend'\n",
    "if str(BACKEND_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BACKEND_DIR))\n",
    "\n",
    "os.chdir(BACKEND_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balas\\AppData\\Roaming\\Python\\Python314\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "table_name",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "16c2e67d-89a1-4f62-b2cc-feca79079774",
       "rows": [
        [
         "0",
         "chunks"
        ],
        [
         "1",
         "documents"
        ],
        [
         "2",
         "feedback"
        ],
        [
         "3",
         "holographic_storage"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feedback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holographic_storage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            table_name\n",
       "0               chunks\n",
       "1            documents\n",
       "2             feedback\n",
       "3  holographic_storage"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from app.core.database import db_manager\n",
    "\n",
    "await db_manager.init_postgres()\n",
    "\n",
    "async with db_manager.pg_pool.acquire() as conn:\n",
    "    table_info = await conn.fetch('''\n",
    "        SELECT table_name\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name\n",
    "    ''')\n",
    "\n",
    "tables = [r['table_name'] for r in table_info]\n",
    "pd.DataFrame({'table_name': tables})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "c04346d5-de9d-4c53-90da-71c10ea2d929",
       "rows": [
        [
         "0",
         "45",
         "Large_language_Model.pdf",
         "2026-02-13 14:49:11.069348"
        ],
        [
         "1",
         "44",
         "Holographic_Storage.pdf",
         "2026-02-13 14:48:50.267169"
        ],
        [
         "2",
         "43",
         "Holographic_data_storage_technology.pdf",
         "2026-02-13 14:47:55.456234"
        ],
        [
         "3",
         "42",
         "Graph_databases.pdf",
         "2026-02-13 14:47:27.800211"
        ],
        [
         "4",
         "41",
         "A_New_Swarm_Intelligence_Coordination_Model_Inspir.pdf",
         "2026-02-13 14:47:08.481283"
        ],
        [
         "5",
         "40",
         "NBala_swamy_resume.pdf",
         "2026-02-06 06:56:39.583519"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>Large_language_Model.pdf</td>\n",
       "      <td>2026-02-13 14:49:11.069348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Holographic_Storage.pdf</td>\n",
       "      <td>2026-02-13 14:48:50.267169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>Holographic_data_storage_technology.pdf</td>\n",
       "      <td>2026-02-13 14:47:55.456234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Graph_databases.pdf</td>\n",
       "      <td>2026-02-13 14:47:27.800211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>A_New_Swarm_Intelligence_Coordination_Model_In...</td>\n",
       "      <td>2026-02-13 14:47:08.481283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>NBala_swamy_resume.pdf</td>\n",
       "      <td>2026-02-06 06:56:39.583519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           filename  \\\n",
       "0  45                           Large_language_Model.pdf   \n",
       "1  44                            Holographic_Storage.pdf   \n",
       "2  43            Holographic_data_storage_technology.pdf   \n",
       "3  42                                Graph_databases.pdf   \n",
       "4  41  A_New_Swarm_Intelligence_Coordination_Model_In...   \n",
       "5  40                             NBala_swamy_resume.pdf   \n",
       "\n",
       "                  created_at  \n",
       "0 2026-02-13 14:49:11.069348  \n",
       "1 2026-02-13 14:48:50.267169  \n",
       "2 2026-02-13 14:47:55.456234  \n",
       "3 2026-02-13 14:47:27.800211  \n",
       "4 2026-02-13 14:47:08.481283  \n",
       "5 2026-02-06 06:56:39.583519  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with db_manager.pg_pool.acquire() as conn:\n",
    "    docs = await conn.fetch('''\n",
    "        SELECT id, filename, created_at\n",
    "        FROM documents\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 20\n",
    "    ''')\n",
    "\n",
    "pd.DataFrame([dict(r) for r in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "document_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "content_preview",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d2c5097c-a639-4126-954c-30fb7c200f53",
       "rows": [
        [
         "0",
         "566",
         "45",
         "205",
         "Moreover, for scientific writing, LLMs can help researchers draft documents, suggest improvements, and ensure adherence to specific formatting guidelines [459, 460]. This not only saves time but also improves the clarity of scien- tific communication, enabling interdisciplinary teams to work togethe"
        ],
        [
         "1",
         "565",
         "45",
         "204",
         "Task Dataset/Benchmark Top-1 Top-2 Top-3 Model (Size)Score (N-shots)Model (Size)Score (N-shots) Model (Size) Score (N-shots) Multi-Task BIG-bench (B) Chinchilla (70B)65.1 (5-shot) Gopher (280B)53.97 (5-shot) PaLM (540B) 53.7 (5-shot) MMLU (B) GPT-4 (-) 86.4 (5-shot) Gemini (Ultra)83.7 (5-shot)Flan-P"
        ],
        [
         "2",
         "564",
         "45",
         "203",
         "In addition, LLMs can aid scientists 32 Table 12: Performance comparison of top performing LLMs across various NLU and NLG tasks. Here, “N-Shots” indicate the number of example prompts provided to the model during the evaluation, representing its capability in few-shot or zero-shot learning settings"
        ],
        [
         "3",
         "563",
         "45",
         "202",
         "They can generate real-time transcriptions for the hear- ing impaired, offer reading assistance for the visually impaired, and simplify complex texts for those with learning disabili- ties [451]. As LLMs continue to evolve, their applications in education can benefit more students and teachers from "
        ],
        [
         "4",
         "562",
         "45",
         "201",
         "For students, by analyzing their learning styles, performance, and preferences, LLMs can provide customized study materials and practice questions to develop personalized learning experiences [452]. For teachers, LLMs can help to create lesson plans and grade assignments and generate diverse and inc"
        ],
        [
         "5",
         "561",
         "45",
         "200",
         "They can also simulate patient interactions, enabling students to practice and improve their clinical skills. At a broader level, LLMs can assist in public health initiatives by analyzing media data to detect disease out- breaks, monitor public sentiment towards health policies, and disseminate heal"
        ],
        [
         "6",
         "560",
         "45",
         "199",
         "Moreover, LLMs can also enhance patient interactions with healthcare systems; e.g., they can be used in chatbot applica- tions [439, 440, 441] to answer patient queries about symptoms or medications, schedule appointments, and even provide es- sential health advice. For medical research, LLMs are us"
        ],
        [
         "7",
         "559",
         "45",
         "198",
         "Moreover, LLMs play a cru- cial role in data analysis, where they can filter large volumes of text data, summarize key points, and find patterns that would take humans much longer to identify [435]. Despite their wide- ranging applications, it is essential to remember that LLMs, similar to any AI sy"
        ],
        [
         "8",
         "558",
         "45",
         "197",
         "This allows them to perform tasks ranging from simple language translation and question-answering to more complex tasks like summarization, text generation, and even program- ming help [432]. The utility of LLMs is further enhanced by their ability to adapt to the specific style and tone of the text"
        ],
        [
         "9",
         "557",
         "45",
         "196",
         "LLMs, which are capable of understanding and generating human-like text, have found meaningful applications across a variety of fields. This section provides an overview of LLM applications in medicine, education, science, mathematics, law, finance, robotics, and coding. While each of these domains "
        ],
        [
         "10",
         "556",
         "45",
         "195",
         "It is a tool in the fight against online hate speech, offering binary and multi-label variants for robust content moderation. StereoSet [409]: StereoSet is a comprehensive dataset de- signed to measure and evaluate the presence of stereotypical biases in language models. It focuses on four key domai"
        ],
        [
         "11",
         "555",
         "45",
         "194",
         "PAWS-X [399]:PAWS-X, or Cross-lingual Paraphrase Adver- saries from Word Scrambling, is a multilingual version of the 31 PAWS [430] dataset for paraphrase identification. It includes examples in seven languages and is designed to evaluate the performance of cross-lingual paraphrase identification mo"
        ],
        [
         "12",
         "554",
         "45",
         "193",
         "HumanEval [141]: A dataset for evaluating the problem- solving ability of AI models, which includes a diverse set of tasks that require various cognitive abilities, making it a com- prehensive tool for assessing general intelligence in AI. StrategyQA [349]: A question-answering dataset that re- quir"
        ],
        [
         "13",
         "553",
         "45",
         "192",
         "Math23k [383]: This one challenges a model’s ability to un- derstand and solve mathematical word problems. It contains 23,000 Chinese arithmetic word problems that require models to perform reasoning and computation based on the problem description. GSM8K [384]: A dataset of diverse grade school mat"
        ],
        [
         "14",
         "552",
         "45",
         "191",
         "WebQA [367]: A dataset for open-domain question answering, WebQA offers a large collection of web-based question-answer pairs. It is designed to assess the ability of AI models to under- stand and answer questions based on web content. CMRC2018 [369]: This dataset is a test of Chinese language model"
        ],
        [
         "15",
         "551",
         "45",
         "190",
         "SQuADv2 combines the original SQuAD1.1 dataset with over 50,000 unanswerable questions. The aim is to evalu- ate a model’s ability to understand and answer questions based on a given context and to determine when a question is unan- swerable. DROP [365]: DROP, or Discrete Reasoning Over the con- ten"
        ],
        [
         "16",
         "550",
         "45",
         "189",
         "CSQA [358]: The CommonsenseQA is a question-answering dataset that requires commonsense knowledge to evaluate the ability of AI models to understand and answer questions. 5.2.7. Reading Comprehension BoolQ [363]: A dataset derived from Google search queries, BoolQ challenges models to answer binary "
        ],
        [
         "17",
         "549",
         "45",
         "188",
         "Models Training Dataset BIG- bench MMLUBBH RAFTFLANSNI PromptSourceTyDiQAHumanEvalMBPP Truthful/ Bias/ Toxicity T0 Pool of Prompts ✓ WebGPT ELI5 [424], ELI5 fact- check [166], TriviaQA [341], ARC-Challenge [342], ARC- Easy [342], Hand-written data, Demonstrations of humans, Com- parisons between mod"
        ],
        [
         "18",
         "548",
         "45",
         "187",
         "Code ✓ ✓ StarCoder The Stack v1.2 ✓ ✓ ✓ ✓ LLaMA-2 ✓ ✓ ✓ ✓ ✓ ✓ ✓ PaLM-2 Web documents, Code, Books, Maths, Conversation ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 30 Table 11: An illustration of training datasets and evaluation benchmarks used in fine-tuned LLMs. “SNI” is a short of Super-NaturalInsturctions."
        ],
        [
         "19",
         "547",
         "45",
         "186",
         "Books3, OpenWebText2, Stack Exchange, PubMed Abstracts, Wikipedia, PG-19 [242], BookCorpus2, NIH ExPorter, Pile, CC-Stories, RealNews ✓ ✓ ✓ ✓ ✓ AlphaCode Selected GitHub repositories, CodeCon- tests: Codeforces, Description2Code, Co- deNet ✓ Chinchilla MassiveWeb, MassiveText Books, C4, News, GitHub"
        ],
        [
         "20",
         "546",
         "45",
         "185",
         "✓ ✓ Gopher subsets of MassiveWeb Books, C4, News, GitHub and Wikipedia samples from Mas- siveText ✓ ✓ ✓ ✓ ✓ ✓ ✓ ERNIE-3.0 TITANSame as ERNIE 3.0 and ERNIE 3.0 ad- versarial dataset, ERNIE 3.0 controllable dataset ✓ ✓ ✓ ✓ ✓ GPT-NeoX-20BPile [301] ✓ ✓ ✓ ✓ ✓ ✓ OPT RoBERTa [299], Pile [301], PushShift.i"
        ],
        [
         "21",
         "545",
         "45",
         "184",
         "T5 C4 [10] ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ GPT-3 Common Crawl, WebText, Books Cor- pora, Wikipedia ✓ ✓ ✓ ✓ ✓ ✓ mT5 mC4 [11] ✓ ✓ ✓ PanGu-α 1.1TB Chinese Text Corpus ✓ ✓ ✓ ✓ ✓ CPM-2 WuDaoCorpus [109] ✓ ✓ Codex 54 million public repositories from Github ✓ ERNIE-3.0 Chinese text corpora, Baidu Search, Web text, QA-long"
        ],
        [
         "22",
         "544",
         "45",
         "183",
         "COPA [401]: This dataset evaluates a model’s progress in open-domain commonsense causal reasoning. Each question comprises a premise and two alternatives, and the model must select the more plausible alternative, testing a model’s ability to understand and reason about cause and effect. WSC [357]: T"
        ],
        [
         "23",
         "543",
         "45",
         "182",
         "RACE-High [347]: A subset of the RACE [347] dataset, RACE-High consists of high school-level English exam ques- tions. It is designed to evaluate the comprehension ability of models in a more academic and challenging context. QuAC [348]: This dataset simulates an information-seeking dialog between s"
        ],
        [
         "24",
         "542",
         "45",
         "181",
         "ARC-Challenge [342]: A rigorous question-answering dataset, ARC-Challenge includes complex, grade-school level questions that demand reasoning beyond simple retrieval, test- ing the true comprehension capabilities of models. 5.2.5. Contextual Language Understanding RACE [347]: The RACE dataset is a "
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 25
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>content_preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>566</td>\n",
       "      <td>45</td>\n",
       "      <td>205</td>\n",
       "      <td>Moreover, for scientific writing, LLMs can hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>565</td>\n",
       "      <td>45</td>\n",
       "      <td>204</td>\n",
       "      <td>Task Dataset/Benchmark Top-1 Top-2 Top-3 Model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>564</td>\n",
       "      <td>45</td>\n",
       "      <td>203</td>\n",
       "      <td>In addition, LLMs can aid scientists 32 Table ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>563</td>\n",
       "      <td>45</td>\n",
       "      <td>202</td>\n",
       "      <td>They can generate real-time transcriptions for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>45</td>\n",
       "      <td>201</td>\n",
       "      <td>For students, by analyzing their learning styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>561</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>They can also simulate patient interactions, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>560</td>\n",
       "      <td>45</td>\n",
       "      <td>199</td>\n",
       "      <td>Moreover, LLMs can also enhance patient intera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>559</td>\n",
       "      <td>45</td>\n",
       "      <td>198</td>\n",
       "      <td>Moreover, LLMs play a cru- cial role in data a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>558</td>\n",
       "      <td>45</td>\n",
       "      <td>197</td>\n",
       "      <td>This allows them to perform tasks ranging from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>557</td>\n",
       "      <td>45</td>\n",
       "      <td>196</td>\n",
       "      <td>LLMs, which are capable of understanding and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>556</td>\n",
       "      <td>45</td>\n",
       "      <td>195</td>\n",
       "      <td>It is a tool in the fight against online hate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>555</td>\n",
       "      <td>45</td>\n",
       "      <td>194</td>\n",
       "      <td>PAWS-X [399]:PAWS-X, or Cross-lingual Paraphra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>554</td>\n",
       "      <td>45</td>\n",
       "      <td>193</td>\n",
       "      <td>HumanEval [141]: A dataset for evaluating the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>553</td>\n",
       "      <td>45</td>\n",
       "      <td>192</td>\n",
       "      <td>Math23k [383]: This one challenges a model’s a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>552</td>\n",
       "      <td>45</td>\n",
       "      <td>191</td>\n",
       "      <td>WebQA [367]: A dataset for open-domain questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>551</td>\n",
       "      <td>45</td>\n",
       "      <td>190</td>\n",
       "      <td>SQuADv2 combines the original SQuAD1.1 dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>550</td>\n",
       "      <td>45</td>\n",
       "      <td>189</td>\n",
       "      <td>CSQA [358]: The CommonsenseQA is a question-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>549</td>\n",
       "      <td>45</td>\n",
       "      <td>188</td>\n",
       "      <td>Models Training Dataset BIG- bench MMLUBBH RAF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>548</td>\n",
       "      <td>45</td>\n",
       "      <td>187</td>\n",
       "      <td>Code ✓ ✓ StarCoder The Stack v1.2 ✓ ✓ ✓ ✓ LLaM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>547</td>\n",
       "      <td>45</td>\n",
       "      <td>186</td>\n",
       "      <td>Books3, OpenWebText2, Stack Exchange, PubMed A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>546</td>\n",
       "      <td>45</td>\n",
       "      <td>185</td>\n",
       "      <td>✓ ✓ Gopher subsets of MassiveWeb Books, C4, Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>545</td>\n",
       "      <td>45</td>\n",
       "      <td>184</td>\n",
       "      <td>T5 C4 [10] ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ GPT-3 Common Crawl,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>544</td>\n",
       "      <td>45</td>\n",
       "      <td>183</td>\n",
       "      <td>COPA [401]: This dataset evaluates a model’s p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>543</td>\n",
       "      <td>45</td>\n",
       "      <td>182</td>\n",
       "      <td>RACE-High [347]: A subset of the RACE [347] da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>542</td>\n",
       "      <td>45</td>\n",
       "      <td>181</td>\n",
       "      <td>ARC-Challenge [342]: A rigorous question-answe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  document_id  chunk_index  \\\n",
       "0   566           45          205   \n",
       "1   565           45          204   \n",
       "2   564           45          203   \n",
       "3   563           45          202   \n",
       "4   562           45          201   \n",
       "5   561           45          200   \n",
       "6   560           45          199   \n",
       "7   559           45          198   \n",
       "8   558           45          197   \n",
       "9   557           45          196   \n",
       "10  556           45          195   \n",
       "11  555           45          194   \n",
       "12  554           45          193   \n",
       "13  553           45          192   \n",
       "14  552           45          191   \n",
       "15  551           45          190   \n",
       "16  550           45          189   \n",
       "17  549           45          188   \n",
       "18  548           45          187   \n",
       "19  547           45          186   \n",
       "20  546           45          185   \n",
       "21  545           45          184   \n",
       "22  544           45          183   \n",
       "23  543           45          182   \n",
       "24  542           45          181   \n",
       "\n",
       "                                      content_preview  \n",
       "0   Moreover, for scientific writing, LLMs can hel...  \n",
       "1   Task Dataset/Benchmark Top-1 Top-2 Top-3 Model...  \n",
       "2   In addition, LLMs can aid scientists 32 Table ...  \n",
       "3   They can generate real-time transcriptions for...  \n",
       "4   For students, by analyzing their learning styl...  \n",
       "5   They can also simulate patient interactions, e...  \n",
       "6   Moreover, LLMs can also enhance patient intera...  \n",
       "7   Moreover, LLMs play a cru- cial role in data a...  \n",
       "8   This allows them to perform tasks ranging from...  \n",
       "9   LLMs, which are capable of understanding and g...  \n",
       "10  It is a tool in the fight against online hate ...  \n",
       "11  PAWS-X [399]:PAWS-X, or Cross-lingual Paraphra...  \n",
       "12  HumanEval [141]: A dataset for evaluating the ...  \n",
       "13  Math23k [383]: This one challenges a model’s a...  \n",
       "14  WebQA [367]: A dataset for open-domain questio...  \n",
       "15  SQuADv2 combines the original SQuAD1.1 dataset...  \n",
       "16  CSQA [358]: The CommonsenseQA is a question-an...  \n",
       "17  Models Training Dataset BIG- bench MMLUBBH RAF...  \n",
       "18  Code ✓ ✓ StarCoder The Stack v1.2 ✓ ✓ ✓ ✓ LLaM...  \n",
       "19  Books3, OpenWebText2, Stack Exchange, PubMed A...  \n",
       "20  ✓ ✓ Gopher subsets of MassiveWeb Books, C4, Ne...  \n",
       "21  T5 C4 [10] ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ GPT-3 Common Crawl,...  \n",
       "22  COPA [401]: This dataset evaluates a model’s p...  \n",
       "23  RACE-High [347]: A subset of the RACE [347] da...  \n",
       "24  ARC-Challenge [342]: A rigorous question-answe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOCUMENT_ID = None  # Set an integer id to inspect a specific document's chunks.\n",
    "\n",
    "query = '''\n",
    "    SELECT id, document_id, chunk_index, LEFT(content, 300) AS content_preview\n",
    "    FROM chunks\n",
    "'''\n",
    "params = []\n",
    "if DOCUMENT_ID is not None:\n",
    "    query += ' WHERE document_id = $1'\n",
    "    params = [DOCUMENT_ID]\n",
    "query += ' ORDER BY id DESC LIMIT 25'\n",
    "\n",
    "async with db_manager.pg_pool.acquire() as conn:\n",
    "    rows = await conn.fetch(query, *params)\n",
    "\n",
    "pd.DataFrame([dict(r) for r in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await db_manager.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
