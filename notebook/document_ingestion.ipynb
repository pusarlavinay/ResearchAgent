{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Ingestion\n",
    "\n",
    "Ingest one or more files into PostgreSQL + vector storage using the project chunker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Researchaiagent\\Data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "if (ROOT / 'backend').exists():\n",
    "    PROJECT_ROOT = ROOT\n",
    "elif ROOT.name == 'notebook':\n",
    "    PROJECT_ROOT = ROOT.parent\n",
    "else:\n",
    "    PROJECT_ROOT = ROOT\n",
    "\n",
    "BACKEND_DIR = PROJECT_ROOT / 'backend'\n",
    "DATA_DIR = PROJECT_ROOT / 'Data'\n",
    "if str(BACKEND_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BACKEND_DIR))\n",
    "\n",
    "os.chdir(BACKEND_DIR)\n",
    "print('Data directory:', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balas\\AppData\\Roaming\\Python\\Python314\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from app.core.database import db_manager\n",
    "from app.services.ingestion import chunker\n",
    "\n",
    "await db_manager.init_postgres()\n",
    "db_manager.init_neo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files selected: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Researchaiagent\\\\Data\\\\A_New_Swarm_Intelligence_Coordination_Model_Inspir.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Graph_databases.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Holographic_data_storage_technology.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Holographic_Storage.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Large_language_Model.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Neuromorphic_Memory.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\quantum inspired Retrival,searching.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Speculative_RAG.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Survey_SwarmIntelligence.pdf',\n",
       " 'C:\\\\Researchaiagent\\\\Data\\\\Temporial_Knowledge_graph.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option A: set explicit file paths\n",
    "FILES_TO_INGEST = [\n",
    "    # str(DATA_DIR / 'sample.pdf'),\n",
    "]\n",
    "\n",
    "# Option B: auto-discover supported files in Data/\n",
    "if not FILES_TO_INGEST:\n",
    "    FILES_TO_INGEST = [\n",
    "        str(p)\n",
    "        for p in DATA_DIR.rglob('*')\n",
    "        if p.suffix.lower() in {'.pdf', '.txt', '.docx'}\n",
    "    ]\n",
    "\n",
    "print(f'Files selected: {len(FILES_TO_INGEST)}')\n",
    "FILES_TO_INGEST[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: C:\\Researchaiagent\\Data\\A_New_Swarm_Intelligence_Coordination_Model_Inspir.pdf -> document_id=41\n",
      "OK: C:\\Researchaiagent\\Data\\Graph_databases.pdf -> document_id=42\n",
      "OK: C:\\Researchaiagent\\Data\\Holographic_data_storage_technology.pdf -> document_id=43\n",
      "OK: C:\\Researchaiagent\\Data\\Holographic_Storage.pdf -> document_id=44\n",
      "OK: C:\\Researchaiagent\\Data\\Large_language_Model.pdf -> document_id=45\n",
      "OK: C:\\Researchaiagent\\Data\\Neuromorphic_Memory.pdf -> document_id=46\n",
      "OK: C:\\Researchaiagent\\Data\\quantum inspired Retrival,searching.pdf -> document_id=47\n",
      "OK: C:\\Researchaiagent\\Data\\Speculative_RAG.pdf -> document_id=48\n",
      "OK: C:\\Researchaiagent\\Data\\Survey_SwarmIntelligence.pdf -> document_id=49\n",
      "FAILED: C:\\Researchaiagent\\Data\\Temporial_Knowledge_graph.pdf -> invalid byte sequence for encoding \"UTF8\": 0x00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'file': 'C:\\\\Researchaiagent\\\\Data\\\\A_New_Swarm_Intelligence_Coordination_Model_Inspir.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 41},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Graph_databases.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 42},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Holographic_data_storage_technology.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 43},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Holographic_Storage.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 44},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Large_language_Model.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 45},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Neuromorphic_Memory.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 46},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\quantum inspired Retrival,searching.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 47},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Speculative_RAG.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 48},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Survey_SwarmIntelligence.pdf',\n",
       "  'status': 'ok',\n",
       "  'document_id': 49},\n",
       " {'file': 'C:\\\\Researchaiagent\\\\Data\\\\Temporial_Knowledge_graph.pdf',\n",
       "  'status': 'failed',\n",
       "  'error': 'invalid byte sequence for encoding \"UTF8\": 0x00'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingestion_results = []\n",
    "\n",
    "for fp in FILES_TO_INGEST:\n",
    "    try:\n",
    "        doc_id = await chunker.process_document(fp)\n",
    "        ingestion_results.append({'file': fp, 'status': 'ok', 'document_id': doc_id})\n",
    "        print(f'OK: {fp} -> document_id={doc_id}')\n",
    "    except Exception as exc:\n",
    "        ingestion_results.append({'file': fp, 'status': 'failed', 'error': str(exc)})\n",
    "        print(f'FAILED: {fp} -> {exc}')\n",
    "\n",
    "ingestion_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await db_manager.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
